\documentclass[10pt]{article}
\usepackage{geometry}
\geometry{a4paper, total={170mm,257mm}, left=20mm, top=20mm}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}

\usepackage{amsmath}
\usepackage{amssymb}

\usepackage[]{algorithm2e}

\usepackage{hyperref}

\title{Norbert Health tests}
\author{Oussama Ennafii}

\begin{document}
    \maketitle

    \section*{Computer Vision}
        \subsection*{\# 1}
            In order to register the two images, one can make use of a standard procedure in 3D vision for finding a rigid transformation (RANSAC) from one image to the other.
            This supposes that both images do not suffer from distortion.
            This process relies on three steps:
            \begin{enumerate}
                \item Detect invariant interest points based on efficient methods such as SIFT, SURF or ORB.
                \item Match the interest points based on their descriptors.
                \item Use a RANSAC derived method to find the corresponding homography which will be robust to outlier matches.
            \end{enumerate}
            This is described in details in Alg.~\ref{alg::ransac_homography}.

            \begin{algorithm}[htb]
                \KwData{\texttt{lwir\_image}, \texttt{gray\_image}, \texttt{interest\_point\_type} \(\in \{SIFT, SURF, ORB\}\), \texttt{descriptor\_distance}, \texttt{min\_matches}}
                \KwResult{Registered LWIR image.}

                lwir\_points, lwir\_descriptors = compute\_interest\_points(\texttt{lwir\_image}, \texttt{interest\_point\_type})\;
                gray\_points, gray\_descriptors = compute\_interest\_points(\texttt{gray\_image}, \texttt{interest\_point\_type})\;

                matches = knn\_matches(lwir\_descriptors, gray\_descriptors, \texttt{descriptor\_distance})\;
                fitered\_matches = lowe\_ratio\_test(matches, ratio = 0.7)\;
                \If{\(\vert\)fitered\_matches\(\vert\) < \texttt{min\_matches}}{
                    raise runtime\_error("Insufficient matches to compute registration")\;
                }
                \(H\) = compute\_homography(lwir\_points, gray\_points, matches)\;
                registered\_lwir\_image = apply\_homography(\texttt{lwir\_image}, \(H\))\;
                \caption{\label{alg::ransac_homography} RANSAC based registration.}
            \end{algorithm}

            Since both images do not have the same domain the descriptors may not be well suited in this case.
            \cite{huo2011multilevel} proposes the use a restricted SURF or SIFT in scale to alleviate this problem.
            In order to solve this problem of descriptor domain mismatch, other approaches could be used.
            One way to do so would be to learn a useful distance function between these descriptors.
            Another way would rely on extracting edges (with Canny Edge detector for instance) and trying to match the corresponding edges (with Iterative Closest Point (ICP) for example).

            LWIR images once registered could be used to compute a thermal (heat) map for a patient for instance.
        
        \subsection*{\# 2}
            Check folder \texttt{3d\_volume}.

    \section*{Audio coughing detection}
        Since the intraclass variance of the \texttt{breathing} class is very high compared to \texttt{coughing} class, the first thing to be done is to consider a mutliclass classification instead of a binary one.
        These classes would be: \texttt{coughing}, \texttt{normal breathing}, \texttt{wheezing}, \texttt{snoring}, \texttt{gasping}, \texttt{panting} and \texttt{snorting}.
        There are in total seven classes.
        For the moment classes are supposed to be exclusive (i.e. not a multilabel problem) if we suppose that observations are small in length.

        We suppose that all audio files have the same number of channels, the same sampling resolution and the same length.
        Different approaches could be used.
        Each one is detailed in the following sectionss.

        The dataset should be divided to two sets.
        A validation set containing a representative amount of each class, containing ideally 10\% of signals in total for instance.
        The goal of such a set is to control the performance of each approach.
        The rest is used for training using a 10-fold stratified cross validation approach in order to calibrate the parameters of the used models.

        \subsection*{Naive approach}
            Use the Mel spectrogram to respresent the signal.
            The latter relies on respresenting the signal by a windowed fourier transform with frequencies mapped to the Mel scale.
            In order to reduce the number of coefficients, one would compute a histogram for each Mel frequency across time.
            The resulting matrix (\(number\_of\_frequencies \times number\_of\_bins\)) will be flattened to obtain a feature vector per audio signal.
            This feature vector will be fed to a supervised classifier such as SVM or Random Forest.
        
        \subsection*{Scattering transform}
            The scattering transform could be seen as a multiscale generalization of the Mel spectrogram~\cite{anden2011multiscale}.
            As such, instead of computing the Mel spectrogram as in the previous approach, we can compute the scattering transform of each signal.
            This will result in a cascade of coefficients that could be reduced using once again a histogram.
            The resulting feature vector is then fed to a classifier as before.

        \subsection*{CNN on Mel spectrogram}
            The Mel spectrogram is seen here as a single channel image.
            Based on this observation, one way of computing better features would be to train a single channel CNN with a cross entropy loss.
            The learned filters would look at neighboring times and frequencies for short range (in time and in frequencies) patterns in the signal.

        \subsection*{Naive LSTM}
            Another approach would be the use the Recurrent neural networks for classifying the audio signals.
            Since the whole signal is classified, a long range in time is needed.
            That is why Long Short Term Memory (LSTM) networks seem like a good choice.
            In this case, the LSTM is applied to the raw signal.
            This is not supposed to work well but should be tried nonetheless as a second baseline.
        
        \subsection*{Mel LSTM}
            Instead of applying the LSTM directly on the signal, first the Mel spectrogram is computed.
            For eah time the network is fed the frequency amplitudes as features.
            This is expected to work best for this problem.

    \bibliographystyle{plain}
    \bibliography{references}
\end{document}
